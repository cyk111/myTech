### 分布式的基石   
- 分布式共识算法   ^55bb69
  - Paxos  
  - Multi Paxos  
  - Gossip 协议  
    
- 从类库到服务  
  ```text  
 - 类库使用连连接器 - 服务使用服务发现 如何确定目标方法的确切位置 ``` - 服务发现  
    - 全限定名  网络中某台主机的精确位置  
    - 端口 代表主机tcp/udp 网络服务程序  
    - 服务标识 与具体应用层协议相关  
      - REST远程服务 标识 url地址  
      - RMI远程服务 标识 stab类中方法  
      - SOAP远程服务 标识 WSDL定义方法  
      - 两种方式 UDDI/DNS   
    - 可靠与可用- 三个必须过程  
      - 服务注册，服务启动，将自己信息表表通知服务中心分 自注册模式，和 k8s 第三方注册模式  
      - 服务的维护  优雅的上下线，维护服务列表正确性  
        - 多协议 http tcp  
        - 多种连接方式（长链接 心跳 探针 进程状态）  
      - 服务的发现 HTTP API或者 DNS lookup 或环境变量(k8s)  
        - 负载均衡  
        - 流量管控  
        - 键值存储  
        - 元数据管理  
        - 业务分组  
    - 可靠性与一致性的取舍，没有好坏，看场景取舍  
      - Eureka 优先保证高可用 各节点采用异步复制  ,ribbon hystrix 故障转移（failover） 快速失败（failfast）  
      - Consul 的选择是优先保证高可靠性 一致性，相对牺牲系统服务发现的可用性。Consul 采用Raft 算法 票；同时采用 Gossip 协议，支持多数据中心之间更大规模的服务同步  
    - 注册中心实现  
      - 可用性与一致性的取舍 是容忍服务列表中出现不可用 还是容忍服务数据不准确的后果，其次考虑 性能高低 功能强大  
      - 分布式kv存储框架实现服务发现 zk(ZAB) etcd(Raft) doozerd  
        - ```text  
 K/V 框架的一个共同特点是在整体较高复杂度的架构和算法的外部，维持着极为简单的应用接口， 只有基本的 CRUD 和 Watch 等少量 API，所以要在上面完成功能齐全的服务发现，很多基础的能力， 譬如服务如何注册、如何做健康检查，等等都必须自己去实现，如今一般也只有“大厂”才会直接基于这些框架去做服务发现了。 ``` - 以基础设施（主要是指 DNS 服务器）来实现服务发现，这类的代表是 SkyDNS、CoreDNS  
      - 专门用于服务发现的框架和工具，这类的代表是 Eureka、Consul 和 Nacos          
  - 网关路由   网关 = 路由器（基础功能）+ 过滤器（可选职能）  
    - 微服务架构，每个服务节点不同的团队负责，都有自己独立互不相同的接口，如果集群缺少一个统一的交互代理人角色，外部服务消费需要知道所有微服务节点在集群中的精确坐标，  
      消费者不仅受网络的限制（不能确保集群中每个节点都能外网访问）、安全限制（自身安全，浏览器同源）、依赖限制（服务坐标信息对外承诺的内容可能随时变动）  
    - 网关首先是路由器，在此基础上，网关也可以做流量过滤器使用，提供额外可选的功能，安全 认证 授权 限流 监控 缓存   
    - 网关主要考量指标： 网络协议层次 + 性能与可用性  
      - 网络层次指负载均衡中 四层流量转发与七层流量代理，在这个角度看  网关与负载均衡器没有什么差别，ingress controller 基于 nginx haproxy, zuul 基于netty  
      - 从目的角度 负载均衡器是根据均衡算法对流量进行平均的路由，网关是根据流量的某种特征进行正确的路由，网络失败特征意味着能支持网络通讯协议，七层网关 四层网关  
    - 性能可用性 ，服务对外的总出口，流量必经之地，所以影响是全局的 系统性的，工作模式 DSR 三角传输模式 请于七层代理，（四层转发，七层代理）  
    - 网络io模型  
      - 两类 同步 异步  
      - 五中模型 异步 同步（阻塞i0 非阻塞io 多路复用io( select epoll kqueue) 信号驱动io）  
    - 网关选择考量  
      - 尽可能的轻量，尽管网关作为服务集群统一的出入口，可以很方便地做安全、认证、授权、限流、监控   
      - 选择成熟产品，性能与可用性平衡  
      - 避免单点风 险，高可用的环境中，在网关前部署负载均衡器或等价路由器，或成熟硬件，这样网关可扩展  
    - BFF 网关 （Backends for Frontends） 后端集群，裁剪、适配、聚合出适应不一样的前端的服务，有助于后端的稳定，也有助于前端的赋能  
          
  - 客户端负载均衡  
    - 服务发现 网关路由 负载均衡 服务容错  
    - 集中式的负载均衡（服务器端负载均衡） 负载均衡器大多只部署在整个服务集群的前端，将用户的请求分流到各个服务进行处理  
    - 集群内部调用采用池化方式更合适  
    - 客户端负载均衡器 全新的、独立位于每个服务前端的、分散式的负载均衡方式，客户端均衡器中最具代表性的产品是 Netflix Ribbon 和 Spring Cloud Load Balancer  
      - 好处  
        - 服务器与均衡器之间信息交换是进程内的方法调用，不存在任何额外网络开销  
        - 不依赖集群边缘设施，所有流量仅在服务集群内部循环  
        - 避免了单点问题  
        - 客户端更加灵活 自由选择负载均衡的参数 策略（随机 轮循 加权 最小链接）  
      - 缺点  
        - 统一进程内，编程语言受限制  
        - 由于是共用一个进程，均衡器的稳定性会直接影响整个服务进程的稳定性，消耗的 CPU、内存等资源也同样影响到服务的可用资源   
        - 由于请求的来源可能是来自集群中任意一个服务节点，而不再是统一来自集中式均衡器   
        - 服务集群的拓扑关系是动态的  
    - 代理均衡器  Proxy Client-Side Load Balancer 客服客户端缓存缺点  
    - 地域 与 区域  
  
- 流量治理   
  - 服务容错  
    - 微服务特征在实施中或多或少都会有妥协，如 分散治理 数据去中心化 轻量级通信机制 演进式设计 容错设计  
    - 程序可能崩溃 节点可能宕机 网络可能中断  
    - 容错策略（弥补）  
      - 故障转移 failover  关键路径的服务均会部署多个副本，达到一定次数或时间 自动切换其他副本  
      - 快速失败 failfast  故障转移要求服务具备幂等性，非幂等服务，重复调用产生脏数据，这样的尽量快速抛出异常 有调用者自行处理  
      - 安全失败 failsafe  调用链路有主路和旁路之分，有些失败不影响核心业务正确性 如扩展点 事件 spring aop注入逻辑，如审计 日志 调用信息，记录错误日志   
      - 沉默失败 failsilent 如大量请求超时，很容易由于某个远程服务的请求堆积而消耗大量的线程、内存、网络等资源，进而影响到整个系统的稳定，认服务提供者一定时间内无法再对外提供服务，不再向它分配请求流量，将错误隔离开来  
      - 故障恢复 failback 一般不单独存在，其他容错策略的补充措施，要求服务必须幂等性，一般对实时性要求不高，也应该设置重试次数  
    - 容错策略（如何获取最大的成功概率）  
      - 并行调用 forking 向多个副本发起调用，只要其中一个返回成功 这次调用才算是成功  
      - 广播调用 broadcast 所有副本都成功 才算是成功 广播调用通常会被用于实现“刷新分布式缓存”这类的操作  
    - 容错设计模式  
      - 断路器模式（ close open half-open） hystrix resilience4j envoy  
        - 服务熔断与服务降级区别，断路器是自动进行熔断快速失败策略，降级不一定错误出现才被执行，主动与被动 降级有的数据流量控制的范围  
      - 舱壁隔离模式  
        - 静默失败模式  
        - 种可行的解决办法是为每个服务单独设立线程池，这些线程池默认不预置活动线程，只用来控制单个服务的最大连接数，还有一种更轻量的可以用来控制服务最大连接数的办法：信号量机制（Semaphore）  
        - 服务调用的角度应用的舱壁隔离设计模式，舱壁隔离模式还可以在更高层、更宏观的场景中使用，不是按调用线程，而是按功能、按子系统、按用户类型等条件来隔离资源都是可以的，譬如，根据用户等级、用户是否 VIP、用户来访的地域等各种因素  
      - 重试模式   
        - 故障转移和故障恢复策略都需要对服务进行重复调用，差别是这些重复调用有可能是同步的，也可能是后台异步进行；有可能会重复调用同一个服务，也可能会调用到服务的其他副本   
        - 前提条件  
          - 仅在主路逻辑的关键服务商进行同步重试  
          - 仅对由瞬时故障导致的失败进行重试  
          - 仅对具备幂等性的服务进行重试  
          - 重试必须有明确的终止条件，常用的终止条件有两种  
            - 超时终止  
            - 次数终止  
      - 熔断、隔离、重试、降级、超时等概念都是建立具有韧性的微服务系统必须的保障措施        
        
  - 流量控制  
    - 依据什么限流 具体如何限流 超额流量如何处理  
    - 流量统计指标  
      - 每秒事务 tps  hps qps  
    - 限流设计模式  
      - 流量计数器 只是针对时间点进行离散的统计  
      - 滑动窗口 滑动时间窗口模式的限流完全解决了流量计数器的缺陷，可以保证任意时间片段内，只需经过简单的调用计数比较，就能控制住请求次数一定不会超过限流的阈值，  
         在单机限流或者分布式服务单点网关中的限流中很常用。不过，这种限流也有其缺点，它通常只适用于否决式限流，超过阈值的流量就必须强制失败或降级，  
         很难进行阻塞等待处理，也就很难在细粒度上对流量曲线进行整形，起不到削峰填谷的作用  
      - 漏斗 元素的先入先出队列（FIFO Queue），队列长度就相当于漏桶的大小，当队列已满时便拒绝新的请求进入。漏桶实现起来很容易，困难在于如何确定漏桶的两个参数：桶的大小和水的流出速率  
      - 令牌桶    
    - 分布式限流   
      - 种常见的简单分布式限流方法是将所有服务的统计结果都存入集中式缓存（如 Redis）中，以实现在集群内的共享，并通过分布式锁、信号量等机制，  
        解决这些数据的读写访问时并发控制的问题。在可以共享统计数据的前提下，原本用于单机的限流模式理论上也是可以应用于分布式环境中的，  
        可是其代价也显而易见：每次服务调用都必须要额外增加一次网络开销，所以这种方法的效率肯定是不高的，流量压力大时，  
        限流本身反倒会显著降低系统的处理能力   
  
- 可靠通讯  
  - 零信任网路  
  - 服务安全  
    
- 可观测（可观测性 可控制性）  
  - 事件日志 logging  
    - 记录离散事件，分析程序行为，调用那些方法，操作那些数据，分析日志 大数据系统  
    - 输出日志 收集 缓冲 聚合加工 索引存储 分析查询  
  - 链路追踪 tracing  
    - 单体时代 栈追踪 stack tracing   
    - 分布式 全链路追踪  
  - 聚合度量 metrics  
    - jmx 内存大小 各分代的用量 峰值的线程数 垃圾收集的吞吐量 频率 监控报警  
    - elk  prometheus